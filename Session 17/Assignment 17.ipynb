{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNST_CIFAR10_AUG.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "outputId": "64151da5-601d-480a-ed96-9d02b429836e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsO_yGxcg5D8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 35\n",
        "l = 40\n",
        "num_filter = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "outputId": "f9b43a66-ef10-41ba-bc7e-066fa02fa617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*2), (3,3), use_bias=False ,padding='same',keras.regularizers.l1_l2(l1=0.01, l2=0.01))(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    input_filter = relu._keras_shape[3]\n",
        "    Conv2D_BottleNeck = Conv2D(int(input_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_filter = 12\n",
        "dropout_rate = 0.2\n",
        "l = 12\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "outputId": "c54befe8-afc9-41fb-dabc-89b9fbaac004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 32, 32, 12)   324         input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 32, 32, 12)   48          conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 32, 32, 12)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 32, 32, 12)   1296        activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_103 (Dropout)           (None, 32, 32, 12)   0           conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_97 (Concatenate)    (None, 32, 32, 24)   0           conv2d_108[0][0]                 \n",
            "                                                                 dropout_103[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 32, 32, 24)   96          concatenate_97[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 32, 32, 24)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 32, 32, 12)   2592        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_104 (Dropout)           (None, 32, 32, 12)   0           conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_98 (Concatenate)    (None, 32, 32, 36)   0           concatenate_97[0][0]             \n",
            "                                                                 dropout_104[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 32, 32, 36)   144         concatenate_98[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 32, 32, 36)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 32, 32, 12)   3888        activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_105 (Dropout)           (None, 32, 32, 12)   0           conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_99 (Concatenate)    (None, 32, 32, 48)   0           concatenate_98[0][0]             \n",
            "                                                                 dropout_105[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 32, 32, 48)   192         concatenate_99[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 32, 32, 48)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 32, 32, 12)   5184        activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_106 (Dropout)           (None, 32, 32, 12)   0           conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_100 (Concatenate)   (None, 32, 32, 60)   0           concatenate_99[0][0]             \n",
            "                                                                 dropout_106[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 32, 32, 60)   240         concatenate_100[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 32, 32, 60)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 32, 32, 12)   6480        activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_107 (Dropout)           (None, 32, 32, 12)   0           conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_101 (Concatenate)   (None, 32, 32, 72)   0           concatenate_100[0][0]            \n",
            "                                                                 dropout_107[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 32, 32, 72)   288         concatenate_101[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 32, 32, 72)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 32, 32, 12)   7776        activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_108 (Dropout)           (None, 32, 32, 12)   0           conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_102 (Concatenate)   (None, 32, 32, 84)   0           concatenate_101[0][0]            \n",
            "                                                                 dropout_108[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 32, 32, 84)   336         concatenate_102[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 32, 32, 84)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 32, 32, 12)   9072        activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_109 (Dropout)           (None, 32, 32, 12)   0           conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_103 (Concatenate)   (None, 32, 32, 96)   0           concatenate_102[0][0]            \n",
            "                                                                 dropout_109[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 32, 32, 96)   384         concatenate_103[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 32, 32, 96)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 32, 32, 12)   10368       activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_110 (Dropout)           (None, 32, 32, 12)   0           conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_104 (Concatenate)   (None, 32, 32, 108)  0           concatenate_103[0][0]            \n",
            "                                                                 dropout_110[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 32, 32, 108)  432         concatenate_104[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 32, 32, 108)  0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 32, 32, 12)   11664       activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_111 (Dropout)           (None, 32, 32, 12)   0           conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_105 (Concatenate)   (None, 32, 32, 120)  0           concatenate_104[0][0]            \n",
            "                                                                 dropout_111[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 32, 32, 120)  480         concatenate_105[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 32, 32, 120)  0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 32, 32, 12)   12960       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_112 (Dropout)           (None, 32, 32, 12)   0           conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_106 (Concatenate)   (None, 32, 32, 132)  0           concatenate_105[0][0]            \n",
            "                                                                 dropout_112[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 32, 32, 132)  528         concatenate_106[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 32, 32, 132)  0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 32, 32, 12)   14256       activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_113 (Dropout)           (None, 32, 32, 12)   0           conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_107 (Concatenate)   (None, 32, 32, 144)  0           concatenate_106[0][0]            \n",
            "                                                                 dropout_113[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 32, 32, 144)  576         concatenate_107[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 32, 32, 144)  0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 32, 32, 12)   15552       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_114 (Dropout)           (None, 32, 32, 12)   0           conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_108 (Concatenate)   (None, 32, 32, 156)  0           concatenate_107[0][0]            \n",
            "                                                                 dropout_114[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 32, 32, 156)  624         concatenate_108[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 32, 32, 156)  0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 32, 32, 78)   12168       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_115 (Dropout)           (None, 32, 32, 78)   0           conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 78)   0           dropout_115[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 78)   312         average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 78)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 12)   8424        activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_116 (Dropout)           (None, 16, 16, 12)   0           conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_109 (Concatenate)   (None, 16, 16, 90)   0           average_pooling2d_9[0][0]        \n",
            "                                                                 dropout_116[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 90)   360         concatenate_109[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 90)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 16, 16, 12)   9720        activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_117 (Dropout)           (None, 16, 16, 12)   0           conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_110 (Concatenate)   (None, 16, 16, 102)  0           concatenate_109[0][0]            \n",
            "                                                                 dropout_117[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 16, 16, 102)  408         concatenate_110[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 16, 16, 102)  0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 16, 16, 12)   11016       activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_118 (Dropout)           (None, 16, 16, 12)   0           conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_111 (Concatenate)   (None, 16, 16, 114)  0           concatenate_110[0][0]            \n",
            "                                                                 dropout_118[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 114)  456         concatenate_111[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 16, 16, 114)  0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 16, 16, 12)   12312       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_119 (Dropout)           (None, 16, 16, 12)   0           conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_112 (Concatenate)   (None, 16, 16, 126)  0           concatenate_111[0][0]            \n",
            "                                                                 dropout_119[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 126)  504         concatenate_112[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 126)  0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 16, 16, 12)   13608       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_120 (Dropout)           (None, 16, 16, 12)   0           conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_113 (Concatenate)   (None, 16, 16, 138)  0           concatenate_112[0][0]            \n",
            "                                                                 dropout_120[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 16, 16, 138)  552         concatenate_113[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 16, 16, 138)  0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 16, 16, 12)   14904       activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_121 (Dropout)           (None, 16, 16, 12)   0           conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_114 (Concatenate)   (None, 16, 16, 150)  0           concatenate_113[0][0]            \n",
            "                                                                 dropout_121[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 16, 16, 150)  600         concatenate_114[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 16, 16, 150)  0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 16, 16, 12)   16200       activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_122 (Dropout)           (None, 16, 16, 12)   0           conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_115 (Concatenate)   (None, 16, 16, 162)  0           concatenate_114[0][0]            \n",
            "                                                                 dropout_122[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 16, 16, 162)  648         concatenate_115[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 16, 16, 162)  0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 16, 16, 12)   17496       activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_123 (Dropout)           (None, 16, 16, 12)   0           conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_116 (Concatenate)   (None, 16, 16, 174)  0           concatenate_115[0][0]            \n",
            "                                                                 dropout_123[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 16, 16, 174)  696         concatenate_116[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 16, 16, 174)  0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 16, 16, 12)   18792       activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_124 (Dropout)           (None, 16, 16, 12)   0           conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_117 (Concatenate)   (None, 16, 16, 186)  0           concatenate_116[0][0]            \n",
            "                                                                 dropout_124[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 16, 16, 186)  744         concatenate_117[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 16, 16, 186)  0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 16, 16, 12)   20088       activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_125 (Dropout)           (None, 16, 16, 12)   0           conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_118 (Concatenate)   (None, 16, 16, 198)  0           concatenate_117[0][0]            \n",
            "                                                                 dropout_125[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 16, 16, 198)  792         concatenate_118[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 16, 16, 198)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 16, 16, 12)   21384       activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_126 (Dropout)           (None, 16, 16, 12)   0           conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_119 (Concatenate)   (None, 16, 16, 210)  0           concatenate_118[0][0]            \n",
            "                                                                 dropout_126[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 16, 16, 210)  840         concatenate_119[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 16, 16, 210)  0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 16, 16, 12)   22680       activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_127 (Dropout)           (None, 16, 16, 12)   0           conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_120 (Concatenate)   (None, 16, 16, 222)  0           concatenate_119[0][0]            \n",
            "                                                                 dropout_127[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 16, 16, 222)  888         concatenate_120[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 16, 16, 222)  0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 16, 16, 111)  24642       activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_128 (Dropout)           (None, 16, 16, 111)  0           conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 8, 8, 111)    0           dropout_128[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 8, 8, 111)    444         average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 8, 8, 111)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 8, 8, 12)     11988       activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_129 (Dropout)           (None, 8, 8, 12)     0           conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_121 (Concatenate)   (None, 8, 8, 123)    0           average_pooling2d_10[0][0]       \n",
            "                                                                 dropout_129[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 8, 8, 123)    492         concatenate_121[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 8, 8, 123)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 8, 8, 12)     13284       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_130 (Dropout)           (None, 8, 8, 12)     0           conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_122 (Concatenate)   (None, 8, 8, 135)    0           concatenate_121[0][0]            \n",
            "                                                                 dropout_130[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 8, 8, 135)    540         concatenate_122[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 8, 8, 135)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 8, 8, 12)     14580       activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_131 (Dropout)           (None, 8, 8, 12)     0           conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_123 (Concatenate)   (None, 8, 8, 147)    0           concatenate_122[0][0]            \n",
            "                                                                 dropout_131[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 8, 8, 147)    588         concatenate_123[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 8, 8, 147)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 8, 8, 12)     15876       activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_132 (Dropout)           (None, 8, 8, 12)     0           conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_124 (Concatenate)   (None, 8, 8, 159)    0           concatenate_123[0][0]            \n",
            "                                                                 dropout_132[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 8, 8, 159)    636         concatenate_124[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 8, 8, 159)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 8, 8, 12)     17172       activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_133 (Dropout)           (None, 8, 8, 12)     0           conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_125 (Concatenate)   (None, 8, 8, 171)    0           concatenate_124[0][0]            \n",
            "                                                                 dropout_133[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 8, 8, 171)    684         concatenate_125[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 8, 8, 171)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 8, 8, 12)     18468       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_134 (Dropout)           (None, 8, 8, 12)     0           conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_126 (Concatenate)   (None, 8, 8, 183)    0           concatenate_125[0][0]            \n",
            "                                                                 dropout_134[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 8, 8, 183)    732         concatenate_126[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 8, 8, 183)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 8, 8, 12)     19764       activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_135 (Dropout)           (None, 8, 8, 12)     0           conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_127 (Concatenate)   (None, 8, 8, 195)    0           concatenate_126[0][0]            \n",
            "                                                                 dropout_135[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 8, 8, 195)    780         concatenate_127[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 8, 8, 195)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 8, 8, 12)     21060       activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_136 (Dropout)           (None, 8, 8, 12)     0           conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_128 (Concatenate)   (None, 8, 8, 207)    0           concatenate_127[0][0]            \n",
            "                                                                 dropout_136[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 8, 8, 207)    828         concatenate_128[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 8, 8, 207)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 8, 8, 12)     22356       activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_137 (Dropout)           (None, 8, 8, 12)     0           conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_129 (Concatenate)   (None, 8, 8, 219)    0           concatenate_128[0][0]            \n",
            "                                                                 dropout_137[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 8, 8, 219)    876         concatenate_129[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 8, 8, 219)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 8, 8, 12)     23652       activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_138 (Dropout)           (None, 8, 8, 12)     0           conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_130 (Concatenate)   (None, 8, 8, 231)    0           concatenate_129[0][0]            \n",
            "                                                                 dropout_138[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 8, 8, 231)    924         concatenate_130[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 8, 8, 231)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 8, 8, 12)     24948       activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_139 (Dropout)           (None, 8, 8, 12)     0           conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_131 (Concatenate)   (None, 8, 8, 243)    0           concatenate_130[0][0]            \n",
            "                                                                 dropout_139[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 8, 8, 243)    972         concatenate_131[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 8, 8, 243)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 8, 8, 12)     26244       activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_140 (Dropout)           (None, 8, 8, 12)     0           conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_132 (Concatenate)   (None, 8, 8, 255)    0           concatenate_131[0][0]            \n",
            "                                                                 dropout_140[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 8, 8, 255)    1020        concatenate_132[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 8, 8, 255)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 8, 8, 127)    32385       activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_141 (Dropout)           (None, 8, 8, 127)    0           conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 4, 4, 127)    0           dropout_141[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 4, 4, 127)    508         average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 4, 4, 127)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 4, 4, 12)     13716       activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_142 (Dropout)           (None, 4, 4, 12)     0           conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_133 (Concatenate)   (None, 4, 4, 139)    0           average_pooling2d_11[0][0]       \n",
            "                                                                 dropout_142[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 4, 4, 139)    556         concatenate_133[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 4, 4, 139)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 4, 4, 12)     15012       activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_143 (Dropout)           (None, 4, 4, 12)     0           conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_134 (Concatenate)   (None, 4, 4, 151)    0           concatenate_133[0][0]            \n",
            "                                                                 dropout_143[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 4, 4, 151)    604         concatenate_134[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 4, 4, 151)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 4, 4, 12)     16308       activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_144 (Dropout)           (None, 4, 4, 12)     0           conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_135 (Concatenate)   (None, 4, 4, 163)    0           concatenate_134[0][0]            \n",
            "                                                                 dropout_144[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 4, 4, 163)    652         concatenate_135[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 4, 4, 163)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 4, 4, 12)     17604       activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_145 (Dropout)           (None, 4, 4, 12)     0           conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_136 (Concatenate)   (None, 4, 4, 175)    0           concatenate_135[0][0]            \n",
            "                                                                 dropout_145[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 4, 4, 175)    700         concatenate_136[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 4, 4, 175)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 4, 4, 12)     18900       activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_146 (Dropout)           (None, 4, 4, 12)     0           conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_137 (Concatenate)   (None, 4, 4, 187)    0           concatenate_136[0][0]            \n",
            "                                                                 dropout_146[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 4, 4, 187)    748         concatenate_137[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 4, 4, 187)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 4, 4, 12)     20196       activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_147 (Dropout)           (None, 4, 4, 12)     0           conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_138 (Concatenate)   (None, 4, 4, 199)    0           concatenate_137[0][0]            \n",
            "                                                                 dropout_147[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 4, 4, 199)    796         concatenate_138[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 4, 4, 199)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 4, 4, 12)     21492       activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_148 (Dropout)           (None, 4, 4, 12)     0           conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_139 (Concatenate)   (None, 4, 4, 211)    0           concatenate_138[0][0]            \n",
            "                                                                 dropout_148[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 4, 4, 211)    844         concatenate_139[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 4, 4, 211)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 4, 4, 12)     22788       activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_149 (Dropout)           (None, 4, 4, 12)     0           conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_140 (Concatenate)   (None, 4, 4, 223)    0           concatenate_139[0][0]            \n",
            "                                                                 dropout_149[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 4, 4, 223)    892         concatenate_140[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 4, 4, 223)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 4, 4, 12)     24084       activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_150 (Dropout)           (None, 4, 4, 12)     0           conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_141 (Concatenate)   (None, 4, 4, 235)    0           concatenate_140[0][0]            \n",
            "                                                                 dropout_150[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 4, 4, 235)    940         concatenate_141[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 4, 4, 235)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 4, 4, 12)     25380       activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_151 (Dropout)           (None, 4, 4, 12)     0           conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_142 (Concatenate)   (None, 4, 4, 247)    0           concatenate_141[0][0]            \n",
            "                                                                 dropout_151[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 4, 4, 247)    988         concatenate_142[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 4, 4, 247)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 4, 4, 12)     26676       activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_152 (Dropout)           (None, 4, 4, 12)     0           conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_143 (Concatenate)   (None, 4, 4, 259)    0           concatenate_142[0][0]            \n",
            "                                                                 dropout_152[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 4, 4, 259)    1036        concatenate_143[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 4, 4, 259)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 4, 4, 12)     27972       activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_153 (Dropout)           (None, 4, 4, 12)     0           conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_144 (Concatenate)   (None, 4, 4, 271)    0           concatenate_143[0][0]            \n",
            "                                                                 dropout_153[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 4, 4, 271)    1084        concatenate_144[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 4, 4, 271)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 2, 2, 271)    0           activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 1084)         0           average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           10850       flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 879,633\n",
            "Trainable params: 863,617\n",
            "Non-trainable params: 16,016\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "fa92231f-78b2-4095-90c2-a18b65f88921"
      },
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "outputId": "78176ed2-9713-408d-9811-10b2168d4116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 87s 2ms/step - loss: 1.2383 - acc: 0.5541 - val_loss: 1.2811 - val_acc: 0.5825\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.8289 - acc: 0.7071 - val_loss: 1.0275 - val_acc: 0.6719\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.6817 - acc: 0.7606 - val_loss: 1.0924 - val_acc: 0.6563\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.5911 - acc: 0.7930 - val_loss: 0.8188 - val_acc: 0.7302\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.5204 - acc: 0.8188 - val_loss: 0.6702 - val_acc: 0.7820\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.4728 - acc: 0.8339 - val_loss: 0.7670 - val_acc: 0.7598\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.4305 - acc: 0.8497 - val_loss: 0.6265 - val_acc: 0.7957\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.3892 - acc: 0.8638 - val_loss: 0.6219 - val_acc: 0.8020\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.3598 - acc: 0.8760 - val_loss: 0.6984 - val_acc: 0.7886\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.3324 - acc: 0.8824 - val_loss: 0.6334 - val_acc: 0.8128\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.3072 - acc: 0.8912 - val_loss: 0.8394 - val_acc: 0.7662\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.2880 - acc: 0.8982 - val_loss: 0.9057 - val_acc: 0.7688\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.2691 - acc: 0.9044 - val_loss: 0.7332 - val_acc: 0.7984\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.2480 - acc: 0.9106 - val_loss: 0.6539 - val_acc: 0.8192\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.2299 - acc: 0.9181 - val_loss: 0.6501 - val_acc: 0.8209\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.2145 - acc: 0.9238 - val_loss: 0.6461 - val_acc: 0.8217\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.2012 - acc: 0.9279 - val_loss: 0.5548 - val_acc: 0.8414\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1943 - acc: 0.9300 - val_loss: 0.6091 - val_acc: 0.8343\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1792 - acc: 0.9343 - val_loss: 0.6280 - val_acc: 0.8400\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1696 - acc: 0.9389 - val_loss: 0.6072 - val_acc: 0.8325\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1552 - acc: 0.9443 - val_loss: 0.6177 - val_acc: 0.8364\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1486 - acc: 0.9472 - val_loss: 0.6168 - val_acc: 0.8511\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1406 - acc: 0.9491 - val_loss: 0.9689 - val_acc: 0.7962\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1418 - acc: 0.9488 - val_loss: 0.5705 - val_acc: 0.8573\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.1302 - acc: 0.9525 - val_loss: 0.6634 - val_acc: 0.8490\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.1207 - acc: 0.9574 - val_loss: 0.5722 - val_acc: 0.8532\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.1161 - acc: 0.9575 - val_loss: 0.6691 - val_acc: 0.8502\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1140 - acc: 0.9591 - val_loss: 0.7873 - val_acc: 0.8284\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1093 - acc: 0.9598 - val_loss: 0.6443 - val_acc: 0.8423\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1044 - acc: 0.9628 - val_loss: 0.6409 - val_acc: 0.8499\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1011 - acc: 0.9630 - val_loss: 0.6923 - val_acc: 0.8496\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0977 - acc: 0.9648 - val_loss: 0.6636 - val_acc: 0.8487\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0910 - acc: 0.9671 - val_loss: 0.8771 - val_acc: 0.8288\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0898 - acc: 0.9683 - val_loss: 0.7055 - val_acc: 0.8549\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0926 - acc: 0.9666 - val_loss: 0.6664 - val_acc: 0.8527\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0845 - acc: 0.9698 - val_loss: 0.7432 - val_acc: 0.8395\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0808 - acc: 0.9708 - val_loss: 0.6865 - val_acc: 0.8496\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0777 - acc: 0.9722 - val_loss: 0.7521 - val_acc: 0.8496\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0797 - acc: 0.9716 - val_loss: 0.6229 - val_acc: 0.8620\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0665 - acc: 0.9759 - val_loss: 0.9191 - val_acc: 0.8285\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0718 - acc: 0.9744 - val_loss: 0.6103 - val_acc: 0.8624\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0708 - acc: 0.9756 - val_loss: 0.6420 - val_acc: 0.8592\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0739 - acc: 0.9738 - val_loss: 0.6430 - val_acc: 0.8665\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0714 - acc: 0.9742 - val_loss: 0.8074 - val_acc: 0.8443\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0654 - acc: 0.9766 - val_loss: 0.7257 - val_acc: 0.8528\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0640 - acc: 0.9772 - val_loss: 0.6229 - val_acc: 0.8708\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0655 - acc: 0.9764 - val_loss: 0.6625 - val_acc: 0.8672\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0609 - acc: 0.9787 - val_loss: 0.6733 - val_acc: 0.8683\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0609 - acc: 0.9785 - val_loss: 0.9499 - val_acc: 0.8273\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0603 - acc: 0.9785 - val_loss: 0.6141 - val_acc: 0.8724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff06e46a2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcWydmIVhZGr",
        "colab_type": "code",
        "outputId": "6c551186-3bd8-41b7-8942-5a71750a8559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5s 459us/step\n",
            "Test loss: 0.6141381495058537\n",
            "Test accuracy: 0.8724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE3lF6EH1r_L",
        "colab_type": "code",
        "outputId": "d016e09c-0d0b-43e2-8dc6-74741b6d8c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "# from google.colab import files\n",
        "# files.download('DNST_model.h5')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}