{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_FEeiyJTJN8",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 16\n",
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLjXv14qTbLp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "018da55b-fe2e-422a-e3c5-9a4c4bc24110"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy  as np\n",
        "import time, math\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import tensorflow.contrib.eager as tfe\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZrBaDQ1TwwV",
        "colab_type": "code",
        "outputId": "d8c9d0f7-e06b-4e24-c09c-18842655f68f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!git clone https://gist.github.com/dc7e60aa487430ea704a8cb3f2c5d6a6.git /tmp/colab_util_repo\n",
        "!mv /tmp/colab_util_repo/colab_util.py colab_util.py \n",
        "!rm -r /tmp/colab_util_repo\n",
        "from colab_util import *\n",
        "drive_handler = GoogleDriveHandler()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/tmp/colab_util_repo'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Total 40 (delta 0), reused 0 (delta 0), pack-reused 40\u001b[K\n",
            "Unpacking objects:   2% (1/40)   \rUnpacking objects:   5% (2/40)   \rUnpacking objects:   7% (3/40)   \rUnpacking objects:  10% (4/40)   \rUnpacking objects:  12% (5/40)   \rUnpacking objects:  15% (6/40)   \rUnpacking objects:  17% (7/40)   \rUnpacking objects:  20% (8/40)   \rUnpacking objects:  22% (9/40)   \rUnpacking objects:  25% (10/40)   \rUnpacking objects:  27% (11/40)   \rUnpacking objects:  30% (12/40)   \rUnpacking objects:  32% (13/40)   \rUnpacking objects:  35% (14/40)   \rUnpacking objects:  37% (15/40)   \rUnpacking objects:  40% (16/40)   \rUnpacking objects:  42% (17/40)   \rUnpacking objects:  45% (18/40)   \rUnpacking objects:  47% (19/40)   \rUnpacking objects:  50% (20/40)   \rUnpacking objects:  52% (21/40)   \rUnpacking objects:  55% (22/40)   \rUnpacking objects:  57% (23/40)   \rUnpacking objects:  60% (24/40)   \rUnpacking objects:  62% (25/40)   \rUnpacking objects:  65% (26/40)   \rUnpacking objects:  67% (27/40)   \rUnpacking objects:  70% (28/40)   \rUnpacking objects:  72% (29/40)   \rUnpacking objects:  75% (30/40)   \rUnpacking objects:  77% (31/40)   \rUnpacking objects:  80% (32/40)   \rUnpacking objects:  82% (33/40)   \rUnpacking objects:  85% (34/40)   \rUnpacking objects:  87% (35/40)   \rUnpacking objects:  90% (36/40)   \rUnpacking objects:  92% (37/40)   \rUnpacking objects:  95% (38/40)   \rUnpacking objects:  97% (39/40)   \rUnpacking objects: 100% (40/40)   \rUnpacking objects: 100% (40/40), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pPjMo6FUbTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Download_File_from_Drive(FileName,DriveFilepath):\n",
        "  drive_handler.download(FileName, target_path=DriveFilepath)\n",
        "\n",
        "def Upload_Images_to_Drive(FileName,TargetDrivePath):\n",
        "  drive_handler.upload(FileName, parent_path=TargetDrivePath)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkaA0TZBX7MT",
        "colab_type": "code",
        "outputId": "9dfcf942-a436-4f40-b303-b7aadf711047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "try:\n",
        "  from generate_tfrecords import CIFAR_TFRecords\n",
        "  from process_tfrecords import create_Train_dataset, create_Test_dataset, parser_test, convert_to_numpy\n",
        "  # from visualization import plot_image\n",
        "except:\n",
        "  !git clone https://github.com/santuhazra1/DEEP_LEARNING_LIBRARY.git /tmp/DEEP_LEARNING_LIBRARY\n",
        "  !mv /tmp/DEEP_LEARNING_LIBRARY/TF_Records/generate_tfrecords.py generate_tfrecords.py\n",
        "  !mv /tmp/DEEP_LEARNING_LIBRARY/TF_Records/process_tfrecords.py process_tfrecords.py\n",
        "  # !mv /tmp/DEEP_LEARNING_LIBRARY/Visualization/visualization.py visualization.py\n",
        "  !rm -r /tmp/DEEP_LEARNING_LIBRARY\n",
        "  from generate_tfrecords import CIFAR_TFRecords\n",
        "  from process_tfrecords import create_Train_dataset, create_Test_dataset, parser_test, convert_to_numpy\n",
        "  # from visualization import plot_image"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/tmp/DEEP_LEARNING_LIBRARY'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/59)\u001b[K\rremote: Counting objects:   3% (2/59)\u001b[K\rremote: Counting objects:   5% (3/59)\u001b[K\rremote: Counting objects:   6% (4/59)\u001b[K\rremote: Counting objects:   8% (5/59)\u001b[K\rremote: Counting objects:  10% (6/59)\u001b[K\rremote: Counting objects:  11% (7/59)\u001b[K\rremote: Counting objects:  13% (8/59)\u001b[K\rremote: Counting objects:  15% (9/59)\u001b[K\rremote: Counting objects:  16% (10/59)\u001b[K\rremote: Counting objects:  18% (11/59)\u001b[K\rremote: Counting objects:  20% (12/59)\u001b[K\rremote: Counting objects:  22% (13/59)\u001b[K\rremote: Counting objects:  23% (14/59)\u001b[K\rremote: Counting objects:  25% (15/59)\u001b[K\rremote: Counting objects:  27% (16/59)\u001b[K\rremote: Counting objects:  28% (17/59)\u001b[K\rremote: Counting objects:  30% (18/59)\u001b[K\rremote: Counting objects:  32% (19/59)\u001b[K\rremote: Counting objects:  33% (20/59)\u001b[K\rremote: Counting objects:  35% (21/59)\u001b[K\rremote: Counting objects:  37% (22/59)\u001b[K\rremote: Counting objects:  38% (23/59)\u001b[K\rremote: Counting objects:  40% (24/59)\u001b[K\rremote: Counting objects:  42% (25/59)\u001b[K\rremote: Counting objects:  44% (26/59)\u001b[K\rremote: Counting objects:  45% (27/59)\u001b[K\rremote: Counting objects:  47% (28/59)\u001b[K\rremote: Counting objects:  49% (29/59)\u001b[K\rremote: Counting objects:  50% (30/59)\u001b[K\rremote: Counting objects:  52% (31/59)\u001b[K\rremote: Counting objects:  54% (32/59)\u001b[K\rremote: Counting objects:  55% (33/59)\u001b[K\rremote: Counting objects:  57% (34/59)\u001b[K\rremote: Counting objects:  59% (35/59)\u001b[K\rremote: Counting objects:  61% (36/59)\u001b[K\rremote: Counting objects:  62% (37/59)\u001b[K\rremote: Counting objects:  64% (38/59)\u001b[K\rremote: Counting objects:  66% (39/59)\u001b[K\rremote: Counting objects:  67% (40/59)\u001b[K\rremote: Counting objects:  69% (41/59)\u001b[K\rremote: Counting objects:  71% (42/59)\u001b[K\rremote: Counting objects:  72% (43/59)\u001b[K\rremote: Counting objects:  74% (44/59)\u001b[K\rremote: Counting objects:  76% (45/59)\u001b[K\rremote: Counting objects:  77% (46/59)\u001b[K\rremote: Counting objects:  79% (47/59)\u001b[K\rremote: Counting objects:  81% (48/59)\u001b[K\rremote: Counting objects:  83% (49/59)\u001b[K\rremote: Counting objects:  84% (50/59)\u001b[K\rremote: Counting objects:  86% (51/59)\u001b[K\rremote: Counting objects:  88% (52/59)\u001b[K\rremote: Counting objects:  89% (53/59)\u001b[K\rremote: Counting objects:  91% (54/59)\u001b[K\rremote: Counting objects:  93% (55/59)\u001b[K\rremote: Counting objects:  94% (56/59)\u001b[K\rremote: Counting objects:  96% (57/59)\u001b[K\rremote: Counting objects:  98% (58/59)\u001b[K\rremote: Counting objects: 100% (59/59)\u001b[K\rremote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects:   2% (1/39)\u001b[K\rremote: Compressing objects:   5% (2/39)\u001b[K\rremote: Compressing objects:   7% (3/39)\u001b[K\rremote: Compressing objects:  10% (4/39)\u001b[K\rremote: Compressing objects:  12% (5/39)\u001b[K\rremote: Compressing objects:  15% (6/39)\u001b[K\rremote: Compressing objects:  17% (7/39)\u001b[K\rremote: Compressing objects:  20% (8/39)\u001b[K\rremote: Compressing objects:  23% (9/39)\u001b[K\rremote: Compressing objects:  25% (10/39)\u001b[K\rremote: Compressing objects:  28% (11/39)\u001b[K\rremote: Compressing objects:  30% (12/39)\u001b[K\rremote: Compressing objects:  33% (13/39)\u001b[K\rremote: Compressing objects:  35% (14/39)\u001b[K\rremote: Compressing objects:  38% (15/39)\u001b[K\rremote: Compressing objects:  41% (16/39)\u001b[K\rremote: Compressing objects:  43% (17/39)\u001b[K\rremote: Compressing objects:  46% (18/39)\u001b[K\rremote: Compressing objects:  48% (19/39)\u001b[K\rremote: Compressing objects:  51% (20/39)\u001b[K\rremote: Compressing objects:  53% (21/39)\u001b[K\rremote: Compressing objects:  56% (22/39)\u001b[K\rremote: Compressing objects:  58% (23/39)\u001b[K\rremote: Compressing objects:  61% (24/39)\u001b[K\rremote: Compressing objects:  64% (25/39)\u001b[K\rremote: Compressing objects:  66% (26/39)\u001b[K\rremote: Compressing objects:  69% (27/39)\u001b[K\rremote: Compressing objects:  71% (28/39)\u001b[K\rremote: Compressing objects:  74% (29/39)\u001b[K\rremote: Compressing objects:  76% (30/39)\u001b[K\rremote: Compressing objects:  79% (31/39)\u001b[K\rremote: Compressing objects:  82% (32/39)\u001b[K\rremote: Compressing objects:  84% (33/39)\u001b[K\rremote: Compressing objects:  87% (34/39)\u001b[K\rremote: Compressing objects:  89% (35/39)\u001b[K\rremote: Compressing objects:  92% (36/39)\u001b[K\rremote: Compressing objects:  94% (37/39)\u001b[K\rremote: Compressing objects:  97% (38/39)\u001b[K\rremote: Compressing objects: 100% (39/39)\u001b[K\rremote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 59 (delta 14), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:   1% (1/59)   \rUnpacking objects:   3% (2/59)   \rUnpacking objects:   5% (3/59)   \rUnpacking objects:   6% (4/59)   \rUnpacking objects:   8% (5/59)   \rUnpacking objects:  10% (6/59)   \rUnpacking objects:  11% (7/59)   \rUnpacking objects:  13% (8/59)   \rUnpacking objects:  15% (9/59)   \rUnpacking objects:  16% (10/59)   \rUnpacking objects:  18% (11/59)   \rUnpacking objects:  20% (12/59)   \rUnpacking objects:  22% (13/59)   \rUnpacking objects:  23% (14/59)   \rUnpacking objects:  25% (15/59)   \rUnpacking objects:  27% (16/59)   \rUnpacking objects:  28% (17/59)   \rUnpacking objects:  30% (18/59)   \rUnpacking objects:  32% (19/59)   \rUnpacking objects:  33% (20/59)   \rUnpacking objects:  35% (21/59)   \rUnpacking objects:  37% (22/59)   \rUnpacking objects:  38% (23/59)   \rUnpacking objects:  40% (24/59)   \rUnpacking objects:  42% (25/59)   \rUnpacking objects:  44% (26/59)   \rUnpacking objects:  45% (27/59)   \rUnpacking objects:  47% (28/59)   \rUnpacking objects:  49% (29/59)   \rUnpacking objects:  50% (30/59)   \rUnpacking objects:  52% (31/59)   \rUnpacking objects:  54% (32/59)   \rUnpacking objects:  55% (33/59)   \rUnpacking objects:  57% (34/59)   \rUnpacking objects:  59% (35/59)   \rUnpacking objects:  61% (36/59)   \rUnpacking objects:  62% (37/59)   \rUnpacking objects:  64% (38/59)   \rUnpacking objects:  66% (39/59)   \rUnpacking objects:  67% (40/59)   \rUnpacking objects:  69% (41/59)   \rUnpacking objects:  71% (42/59)   \rUnpacking objects:  72% (43/59)   \rUnpacking objects:  74% (44/59)   \rUnpacking objects:  76% (45/59)   \rUnpacking objects:  77% (46/59)   \rUnpacking objects:  79% (47/59)   \rUnpacking objects:  81% (48/59)   \rUnpacking objects:  83% (49/59)   \rUnpacking objects:  84% (50/59)   \rUnpacking objects:  86% (51/59)   \rUnpacking objects:  88% (52/59)   \rUnpacking objects:  89% (53/59)   \rUnpacking objects:  91% (54/59)   \rUnpacking objects:  93% (55/59)   \rUnpacking objects:  94% (56/59)   \rUnpacking objects:  96% (57/59)   \rUnpacking objects:  98% (58/59)   \rUnpacking objects: 100% (59/59)   \rUnpacking objects: 100% (59/59), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEDyDK7uhq0f",
        "colab_type": "code",
        "outputId": "d5d9b542-95d2-4e4f-a000-09143d606909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  Download_File_from_Drive('eval.tfrecords','EVA_Phase_1/CIFAR10_Data/eval.tfrecords')\n",
        "  Download_File_from_Drive('train.tfrecords','EVA_Phase_1/CIFAR10_Data/train.tfrecords')\n",
        "  print('Download Successful')\n",
        "except:\n",
        "  data_dir = '/content/'\n",
        "  CIFAR_TFRecords(data_dir)\n",
        "  Upload_Images_to_Drive('cifar-10-python.tar.gz','EVA_Phase_1/CIFAR10_Data/')\n",
        "  Upload_Images_to_Drive('eval.tfrecords','EVA_Phase_1/CIFAR10_Data/')\n",
        "  Upload_Images_to_Drive('train.tfrecords','EVA_Phase_1/CIFAR10_Data/')\n",
        "  print('Upload Successful')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download Successful\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_ADbuqEjpwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename_train = '/content/train.tfrecords' \n",
        "filename_test = '/content/eval.tfrecords' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4wJZsHxJn9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_epochs = 50\n",
        "num_classes = 10\n",
        "l = 12\n",
        "num_filter = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2\n",
        "img_height = 32\n",
        "img_width = 32\n",
        "channel = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAcCzLIDlnct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = tf.keras.layers.BatchNormalization()(temp)\n",
        "        relu = tf.keras.layers.Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = tf.keras.layers.Conv2D(int(num_filter*2), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = tf.keras.layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = tf.keras.layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp\n",
        "\n",
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = tf.keras.layers.BatchNormalization()(input)\n",
        "    relu = tf.keras.layers.Activation('relu')(BatchNorm)\n",
        "    input_filter = relu.get_shape().as_list()[3]\n",
        "    Conv2D_BottleNeck = tf.keras.layers.Conv2D(int(input_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = tf.keras.layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = tf.keras.layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg\n",
        "\n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = tf.keras.layers.BatchNormalization()(input)\n",
        "    relu = tf.keras.layers.Activation('relu')(BatchNorm)\n",
        "    AvgPooling = tf.keras.layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = tf.keras.layers.Flatten()(AvgPooling)\n",
        "    output = tf.keras.layers.Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output\n",
        "\n",
        "input = tf.keras.layers.Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = tf.keras.layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iupTbhErltoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "977a3a6c-fba7-477a-efd1-f48cdf69d132"
      },
      "source": [
        "model = tf.keras.models.Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 12)   324         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 12)   48          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 12)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 24)   2592        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32, 32, 24)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 36)   0           conv2d[0][0]                     \n",
            "                                                                 dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 36)   144         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 36)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 24)   7776        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 24)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 60)   0           concatenate[0][0]                \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 60)   240         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 60)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 24)   12960       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 24)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 84)   0           concatenate_1[0][0]              \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 84)   336         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 84)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 24)   18144       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 24)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 108)  0           concatenate_2[0][0]              \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 108)  432         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 108)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 24)   23328       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32, 32, 24)   0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 132)  0           concatenate_3[0][0]              \n",
            "                                                                 dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 132)  528         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 132)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 24)   28512       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32, 32, 24)   0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 156)  0           concatenate_4[0][0]              \n",
            "                                                                 dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 156)  624         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 156)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 24)   33696       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32, 32, 24)   0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 180)  0           concatenate_5[0][0]              \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 180)  720         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 180)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 24)   38880       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 32, 32, 24)   0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 204)  0           concatenate_6[0][0]              \n",
            "                                                                 dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 204)  816         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 204)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 24)   44064       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 32, 32, 24)   0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 228)  0           concatenate_7[0][0]              \n",
            "                                                                 dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 228)  912         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 228)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 24)   49248       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 32, 32, 24)   0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 252)  0           concatenate_8[0][0]              \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 252)  1008        concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 252)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 24)   54432       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 32, 32, 24)   0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 276)  0           concatenate_9[0][0]              \n",
            "                                                                 dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 276)  1104        concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 276)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 24)   59616       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32, 32, 24)   0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 300)  0           concatenate_10[0][0]             \n",
            "                                                                 dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 300)  1200        concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 300)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 150)  45000       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32, 32, 150)  0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 150)  0           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 150)  600         average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 150)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 24)   32400       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 16, 16, 24)   0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 16, 16, 174)  0           average_pooling2d[0][0]          \n",
            "                                                                 dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 174)  696         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 174)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 24)   37584       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 16, 16, 24)   0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 16, 16, 198)  0           concatenate_12[0][0]             \n",
            "                                                                 dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 198)  792         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 198)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 24)   42768       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 16, 16, 24)   0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 16, 16, 222)  0           concatenate_13[0][0]             \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 222)  888         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 222)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 24)   47952       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 16, 16, 24)   0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 16, 16, 246)  0           concatenate_14[0][0]             \n",
            "                                                                 dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 246)  984         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 246)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 24)   53136       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 16, 16, 24)   0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 270)  0           concatenate_15[0][0]             \n",
            "                                                                 dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 270)  1080        concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 270)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 24)   58320       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 16, 16, 24)   0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 294)  0           concatenate_16[0][0]             \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 294)  1176        concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 294)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 24)   63504       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 16, 16, 24)   0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 318)  0           concatenate_17[0][0]             \n",
            "                                                                 dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 318)  1272        concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 318)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 24)   68688       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 16, 16, 24)   0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 342)  0           concatenate_18[0][0]             \n",
            "                                                                 dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 342)  1368        concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 342)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 24)   73872       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 16, 16, 24)   0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 366)  0           concatenate_19[0][0]             \n",
            "                                                                 dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 366)  1464        concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 366)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 24)   79056       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 16, 16, 24)   0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 390)  0           concatenate_20[0][0]             \n",
            "                                                                 dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 390)  1560        concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 390)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 24)   84240       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 16, 16, 24)   0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 414)  0           concatenate_21[0][0]             \n",
            "                                                                 dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 414)  1656        concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 414)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 24)   89424       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 16, 16, 24)   0           conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 438)  0           concatenate_22[0][0]             \n",
            "                                                                 dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 438)  1752        concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 438)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 219)  95922       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 16, 16, 219)  0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 8, 8, 219)    0           dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 219)    876         average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 219)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 24)     47304       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 8, 8, 24)     0           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 8, 8, 243)    0           average_pooling2d_1[0][0]        \n",
            "                                                                 dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 243)    972         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 243)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 24)     52488       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 8, 8, 24)     0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 8, 8, 267)    0           concatenate_24[0][0]             \n",
            "                                                                 dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 267)    1068        concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 267)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 24)     57672       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 8, 8, 24)     0           conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 8, 8, 291)    0           concatenate_25[0][0]             \n",
            "                                                                 dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 291)    1164        concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 291)    0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 24)     62856       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 8, 8, 24)     0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 8, 8, 315)    0           concatenate_26[0][0]             \n",
            "                                                                 dropout_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 315)    1260        concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 315)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 24)     68040       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 8, 8, 24)     0           conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 8, 8, 339)    0           concatenate_27[0][0]             \n",
            "                                                                 dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 339)    1356        concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 339)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 24)     73224       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_31 (Dropout)            (None, 8, 8, 24)     0           conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 8, 8, 363)    0           concatenate_28[0][0]             \n",
            "                                                                 dropout_31[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 363)    1452        concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 363)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 24)     78408       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_32 (Dropout)            (None, 8, 8, 24)     0           conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 8, 8, 387)    0           concatenate_29[0][0]             \n",
            "                                                                 dropout_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 387)    1548        concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 387)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 24)     83592       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_33 (Dropout)            (None, 8, 8, 24)     0           conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 8, 8, 411)    0           concatenate_30[0][0]             \n",
            "                                                                 dropout_33[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 411)    1644        concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 411)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 24)     88776       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_34 (Dropout)            (None, 8, 8, 24)     0           conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 8, 8, 435)    0           concatenate_31[0][0]             \n",
            "                                                                 dropout_34[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 435)    1740        concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 435)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 24)     93960       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_35 (Dropout)            (None, 8, 8, 24)     0           conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 8, 8, 459)    0           concatenate_32[0][0]             \n",
            "                                                                 dropout_35[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 459)    1836        concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 459)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 24)     99144       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_36 (Dropout)            (None, 8, 8, 24)     0           conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 8, 8, 483)    0           concatenate_33[0][0]             \n",
            "                                                                 dropout_36[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 483)    1932        concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 483)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 24)     104328      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 8, 8, 24)     0           conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 8, 8, 507)    0           concatenate_34[0][0]             \n",
            "                                                                 dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 507)    2028        concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 507)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 253)    128271      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_38 (Dropout)            (None, 8, 8, 253)    0           conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 4, 4, 253)    0           dropout_38[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 4, 4, 253)    1012        average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 4, 4, 253)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 4, 4, 24)     54648       activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 4, 4, 24)     0           conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 4, 4, 277)    0           average_pooling2d_2[0][0]        \n",
            "                                                                 dropout_39[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 4, 4, 277)    1108        concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 4, 4, 277)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 4, 4, 24)     59832       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 4, 4, 24)     0           conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 4, 4, 301)    0           concatenate_36[0][0]             \n",
            "                                                                 dropout_40[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 4, 4, 301)    1204        concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 4, 4, 301)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 4, 4, 24)     65016       activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 4, 4, 24)     0           conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 4, 4, 325)    0           concatenate_37[0][0]             \n",
            "                                                                 dropout_41[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 4, 4, 325)    1300        concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 4, 4, 325)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 4, 4, 24)     70200       activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 4, 4, 24)     0           conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 4, 4, 349)    0           concatenate_38[0][0]             \n",
            "                                                                 dropout_42[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 4, 4, 349)    1396        concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 4, 4, 349)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 4, 4, 24)     75384       activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 4, 4, 24)     0           conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 4, 4, 373)    0           concatenate_39[0][0]             \n",
            "                                                                 dropout_43[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 4, 4, 373)    1492        concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 4, 4, 373)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 4, 4, 24)     80568       activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 4, 4, 24)     0           conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 4, 4, 397)    0           concatenate_40[0][0]             \n",
            "                                                                 dropout_44[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 4, 4, 397)    1588        concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 4, 4, 397)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 4, 4, 24)     85752       activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 4, 4, 24)     0           conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 4, 4, 421)    0           concatenate_41[0][0]             \n",
            "                                                                 dropout_45[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 4, 4, 421)    1684        concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 4, 4, 421)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 4, 4, 24)     90936       activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_46 (Dropout)            (None, 4, 4, 24)     0           conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 4, 4, 445)    0           concatenate_42[0][0]             \n",
            "                                                                 dropout_46[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 4, 4, 445)    1780        concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 4, 4, 445)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 4, 4, 24)     96120       activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, 4, 4, 24)     0           conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 4, 4, 469)    0           concatenate_43[0][0]             \n",
            "                                                                 dropout_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 4, 4, 469)    1876        concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 4, 4, 469)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 4, 4, 24)     101304      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 4, 4, 24)     0           conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 4, 4, 493)    0           concatenate_44[0][0]             \n",
            "                                                                 dropout_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 4, 4, 493)    1972        concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 4, 4, 493)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 4, 4, 24)     106488      activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_49 (Dropout)            (None, 4, 4, 24)     0           conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 4, 4, 517)    0           concatenate_45[0][0]             \n",
            "                                                                 dropout_49[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 4, 4, 517)    2068        concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 4, 4, 517)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 4, 4, 24)     111672      activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_50 (Dropout)            (None, 4, 4, 24)     0           conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 4, 4, 541)    0           concatenate_46[0][0]             \n",
            "                                                                 dropout_50[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 4, 4, 541)    2164        concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 4, 4, 541)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 2, 2, 541)    0           activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2164)         0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           21650       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 3,365,991\n",
            "Trainable params: 3,334,531\n",
            "Non-trainable params: 31,460\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-seBoyp8o5QJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "435bfc98-0e65-429d-86ea-fd8b8ea5b548"
      },
      "source": [
        "import time\n",
        "# TEST TFRecords\n",
        "dataset_test = create_Test_dataset(filename_test,batch_size)\n",
        "\n",
        "sgd = tf.keras.optimizers.SGD(lr=0.005, decay=4e-5, momentum=0.9, nesterov=True)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=sgd,\n",
        "                metrics=['accuracy'])\n",
        "# reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
        "start_time = time.time()\n",
        "for zz in range(1,num_epochs+1):\n",
        "  dataset_train = create_Train_dataset(filename_train,batch_size)\n",
        "  print(\"TrainEpochs number{}/{}\".format(zz,num_epochs))\n",
        "\n",
        "  model.fit_generator(dataset_train,steps_per_epoch=int(50000/batch_size),epochs=1,verbose=1,validation_data=dataset_test)#, callbacks = [reduce_lr_loss])\n",
        "\n",
        "  # print(\"Test Epochs number{}/{}\".format(zz,num_epochs))\n",
        "  # model.evaluate_generator(dataset_test,steps=int(10000/batch_size),verbose=1)\n",
        "  print(\"  \")\n",
        "  print(\"------------------------\",time.time()-start_time)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/process_tfrecords.py:106: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "WARNING:tensorflow:From /content/process_tfrecords.py:107: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/process_tfrecords.py:33: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "TrainEpochs number1/50\n",
            "390/390 [==============================] - 205s 525ms/step - loss: 1.6208 - acc: 0.4037 - val_loss: 2.0731 - val_acc: 0.3753\n",
            "  \n",
            "------------------------ 205.24196076393127\n",
            "TrainEpochs number2/50\n",
            "390/390 [==============================] - 199s 511ms/step - loss: 1.3158 - acc: 0.5224 - val_loss: 1.4714 - val_acc: 0.5406\n",
            "  \n",
            "------------------------ 404.7333092689514\n",
            "TrainEpochs number3/50\n",
            "390/390 [==============================] - 199s 510ms/step - loss: 1.1414 - acc: 0.5918 - val_loss: 1.3702 - val_acc: 0.5697\n",
            "  \n",
            "------------------------ 603.6246430873871\n",
            "TrainEpochs number4/50\n",
            "390/390 [==============================] - 199s 511ms/step - loss: 1.0112 - acc: 0.6400 - val_loss: 1.0844 - val_acc: 0.6538\n",
            "  \n",
            "------------------------ 802.9165003299713\n",
            "TrainEpochs number5/50\n",
            "390/390 [==============================] - 201s 514ms/step - loss: 0.9155 - acc: 0.6748 - val_loss: 0.9441 - val_acc: 0.6981\n",
            "  \n",
            "------------------------ 1003.5801994800568\n",
            "TrainEpochs number6/50\n",
            "390/390 [==============================] - 203s 521ms/step - loss: 0.8488 - acc: 0.6999 - val_loss: 0.9720 - val_acc: 0.7050\n",
            "  \n",
            "------------------------ 1207.0088686943054\n",
            "TrainEpochs number7/50\n",
            "390/390 [==============================] - 203s 520ms/step - loss: 0.7959 - acc: 0.7187 - val_loss: 0.8978 - val_acc: 0.7217\n",
            "  \n",
            "------------------------ 1410.0613911151886\n",
            "TrainEpochs number8/50\n",
            "390/390 [==============================] - 205s 525ms/step - loss: 0.7460 - acc: 0.7351 - val_loss: 0.7826 - val_acc: 0.7559\n",
            "  \n",
            "------------------------ 1615.108479499817\n",
            "TrainEpochs number9/50\n",
            "390/390 [==============================] - 204s 523ms/step - loss: 0.7107 - acc: 0.7514 - val_loss: 0.9768 - val_acc: 0.7095\n",
            "  \n",
            "------------------------ 1819.25834274292\n",
            "TrainEpochs number10/50\n",
            "390/390 [==============================] - 200s 513ms/step - loss: 0.6761 - acc: 0.7624 - val_loss: 1.0083 - val_acc: 0.7309\n",
            "  \n",
            "------------------------ 2019.3441789150238\n",
            "TrainEpochs number11/50\n",
            "390/390 [==============================] - 199s 511ms/step - loss: 0.6525 - acc: 0.7692 - val_loss: 0.8226 - val_acc: 0.7412\n",
            "  \n",
            "------------------------ 2218.7879440784454\n",
            "TrainEpochs number12/50\n",
            "390/390 [==============================] - 199s 510ms/step - loss: 0.6299 - acc: 0.7790 - val_loss: 0.6324 - val_acc: 0.7999\n",
            "  \n",
            "------------------------ 2417.9574847221375\n",
            "TrainEpochs number13/50\n",
            "390/390 [==============================] - 198s 509ms/step - loss: 0.5998 - acc: 0.7879 - val_loss: 0.7700 - val_acc: 0.7675\n",
            "  \n",
            "------------------------ 2616.549992084503\n",
            "TrainEpochs number14/50\n",
            "390/390 [==============================] - 199s 509ms/step - loss: 0.5846 - acc: 0.7945 - val_loss: 0.7738 - val_acc: 0.7723\n",
            "  \n",
            "------------------------ 2815.3198668956757\n",
            "TrainEpochs number15/50\n",
            "390/390 [==============================] - 199s 510ms/step - loss: 0.5652 - acc: 0.8018 - val_loss: 0.6768 - val_acc: 0.7990\n",
            "  \n",
            "------------------------ 3014.4021213054657\n",
            "TrainEpochs number16/50\n",
            "390/390 [==============================] - 200s 513ms/step - loss: 0.5449 - acc: 0.8091 - val_loss: 0.6828 - val_acc: 0.7833\n",
            "  \n",
            "------------------------ 3214.419575214386\n",
            "TrainEpochs number17/50\n",
            "390/390 [==============================] - 203s 521ms/step - loss: 0.5317 - acc: 0.8129 - val_loss: 0.6713 - val_acc: 0.7986\n",
            "  \n",
            "------------------------ 3417.6549632549286\n",
            "TrainEpochs number18/50\n",
            "390/390 [==============================] - 203s 522ms/step - loss: 0.5163 - acc: 0.8195 - val_loss: 0.6512 - val_acc: 0.8091\n",
            "  \n",
            "------------------------ 3621.174096107483\n",
            "TrainEpochs number19/50\n",
            "390/390 [==============================] - 201s 516ms/step - loss: 0.5002 - acc: 0.8239 - val_loss: 0.5581 - val_acc: 0.8268\n",
            "  \n",
            "------------------------ 3822.374095439911\n",
            "TrainEpochs number20/50\n",
            "390/390 [==============================] - 201s 515ms/step - loss: 0.4908 - acc: 0.8286 - val_loss: 0.5634 - val_acc: 0.8283\n",
            "  \n",
            "------------------------ 4023.322037935257\n",
            "TrainEpochs number21/50\n",
            "390/390 [==============================] - 201s 517ms/step - loss: 0.4799 - acc: 0.8319 - val_loss: 0.6514 - val_acc: 0.8128\n",
            "  \n",
            "------------------------ 4224.89995765686\n",
            "TrainEpochs number22/50\n",
            "390/390 [==============================] - 200s 513ms/step - loss: 0.4665 - acc: 0.8369 - val_loss: 0.5266 - val_acc: 0.8370\n",
            "  \n",
            "------------------------ 4425.122838258743\n",
            "TrainEpochs number23/50\n",
            "390/390 [==============================] - 199s 511ms/step - loss: 0.4550 - acc: 0.8411 - val_loss: 0.5876 - val_acc: 0.8274\n",
            "  \n",
            "------------------------ 4624.714256763458\n",
            "TrainEpochs number24/50\n",
            "390/390 [==============================] - 199s 510ms/step - loss: 0.4448 - acc: 0.8438 - val_loss: 0.6938 - val_acc: 0.8058\n",
            "  \n",
            "------------------------ 4823.755281686783\n",
            "TrainEpochs number25/50\n",
            "390/390 [==============================] - 202s 519ms/step - loss: 0.4380 - acc: 0.8468 - val_loss: 0.4917 - val_acc: 0.8528\n",
            "  \n",
            "------------------------ 5026.317333459854\n",
            "TrainEpochs number26/50\n",
            "390/390 [==============================] - 201s 514ms/step - loss: 0.4266 - acc: 0.8513 - val_loss: 0.8566 - val_acc: 0.7699\n",
            "  \n",
            "------------------------ 5226.9758644104\n",
            "TrainEpochs number27/50\n",
            "390/390 [==============================] - 202s 519ms/step - loss: 0.4200 - acc: 0.8532 - val_loss: 0.5180 - val_acc: 0.8437\n",
            "  \n",
            "------------------------ 5429.37804889679\n",
            "TrainEpochs number28/50\n",
            "390/390 [==============================] - 201s 516ms/step - loss: 0.4124 - acc: 0.8556 - val_loss: 0.5464 - val_acc: 0.8453\n",
            "  \n",
            "------------------------ 5630.823845148087\n",
            "TrainEpochs number29/50\n",
            "390/390 [==============================] - 201s 515ms/step - loss: 0.4013 - acc: 0.8606 - val_loss: 0.5150 - val_acc: 0.8485\n",
            "  \n",
            "------------------------ 5831.6547768116\n",
            "TrainEpochs number30/50\n",
            "390/390 [==============================] - 203s 519ms/step - loss: 0.3941 - acc: 0.8627 - val_loss: 0.4499 - val_acc: 0.8671\n",
            "  \n",
            "------------------------ 6034.308533668518\n",
            "TrainEpochs number31/50\n",
            "390/390 [==============================] - 203s 520ms/step - loss: 0.3897 - acc: 0.8640 - val_loss: 0.5663 - val_acc: 0.8392\n",
            "  \n",
            "------------------------ 6237.335342407227\n",
            "TrainEpochs number32/50\n",
            "390/390 [==============================] - 201s 516ms/step - loss: 0.3826 - acc: 0.8640 - val_loss: 0.5372 - val_acc: 0.8480\n",
            "  \n",
            "------------------------ 6438.84170460701\n",
            "TrainEpochs number33/50\n",
            "390/390 [==============================] - 203s 521ms/step - loss: 0.3753 - acc: 0.8686 - val_loss: 0.4667 - val_acc: 0.8601\n",
            "  \n",
            "------------------------ 6642.13888168335\n",
            "TrainEpochs number34/50\n",
            "390/390 [==============================] - 204s 524ms/step - loss: 0.3719 - acc: 0.8701 - val_loss: 0.4599 - val_acc: 0.8657\n",
            "  \n",
            "------------------------ 6846.457386732101\n",
            "TrainEpochs number35/50\n",
            "390/390 [==============================] - 204s 522ms/step - loss: 0.3624 - acc: 0.8724 - val_loss: 0.5817 - val_acc: 0.8456\n",
            "  \n",
            "------------------------ 7050.289733409882\n",
            "TrainEpochs number36/50\n",
            "390/390 [==============================] - 202s 518ms/step - loss: 0.3589 - acc: 0.8758 - val_loss: 0.7087 - val_acc: 0.8007\n",
            "  \n",
            "------------------------ 7252.304110765457\n",
            "TrainEpochs number37/50\n",
            "390/390 [==============================] - 203s 520ms/step - loss: 0.3520 - acc: 0.8759 - val_loss: 0.5392 - val_acc: 0.8480\n",
            "  \n",
            "------------------------ 7455.200531721115\n",
            "TrainEpochs number38/50\n",
            "390/390 [==============================] - 202s 518ms/step - loss: 0.3499 - acc: 0.8771 - val_loss: 0.4645 - val_acc: 0.8668\n",
            "  \n",
            "------------------------ 7657.421252012253\n",
            "TrainEpochs number39/50\n",
            "390/390 [==============================] - 203s 519ms/step - loss: 0.3424 - acc: 0.8783 - val_loss: 0.4681 - val_acc: 0.8670\n",
            "  \n",
            "------------------------ 7860.039848089218\n",
            "TrainEpochs number40/50\n",
            "390/390 [==============================] - 201s 515ms/step - loss: 0.3365 - acc: 0.8811 - val_loss: 0.5950 - val_acc: 0.8406\n",
            "  \n",
            "------------------------ 8061.093964338303\n",
            "TrainEpochs number41/50\n",
            "390/390 [==============================] - 204s 523ms/step - loss: 0.3318 - acc: 0.8830 - val_loss: 0.4976 - val_acc: 0.8669\n",
            "  \n",
            "------------------------ 8264.990379571915\n",
            "TrainEpochs number42/50\n",
            "390/390 [==============================] - 204s 523ms/step - loss: 0.3263 - acc: 0.8846 - val_loss: 0.4351 - val_acc: 0.8744\n",
            "  \n",
            "------------------------ 8469.135439157486\n",
            "TrainEpochs number43/50\n",
            "390/390 [==============================] - 201s 516ms/step - loss: 0.3191 - acc: 0.8878 - val_loss: 0.4866 - val_acc: 0.8685\n",
            "  \n",
            "------------------------ 8670.44125175476\n",
            "TrainEpochs number44/50\n",
            "390/390 [==============================] - 200s 513ms/step - loss: 0.3185 - acc: 0.8863 - val_loss: 0.4266 - val_acc: 0.8791\n",
            "  \n",
            "------------------------ 8870.582866430283\n",
            "TrainEpochs number45/50\n",
            "390/390 [==============================] - 200s 512ms/step - loss: 0.3089 - acc: 0.8929 - val_loss: 0.4360 - val_acc: 0.8783\n",
            "  \n",
            "------------------------ 9070.472121715546\n",
            "TrainEpochs number46/50\n",
            "390/390 [==============================] - 200s 513ms/step - loss: 0.3073 - acc: 0.8915 - val_loss: 0.4798 - val_acc: 0.8688\n",
            "  \n",
            "------------------------ 9270.697273015976\n",
            "TrainEpochs number47/50\n",
            "390/390 [==============================] - 200s 512ms/step - loss: 0.3085 - acc: 0.8901 - val_loss: 0.4218 - val_acc: 0.8787\n",
            "  \n",
            "------------------------ 9470.556685686111\n",
            "TrainEpochs number48/50\n",
            "390/390 [==============================] - 200s 513ms/step - loss: 0.2972 - acc: 0.8954 - val_loss: 0.4048 - val_acc: 0.8818\n",
            "  \n",
            "------------------------ 9670.81079030037\n",
            "TrainEpochs number49/50\n",
            "390/390 [==============================] - 200s 514ms/step - loss: 0.2985 - acc: 0.8949 - val_loss: 0.4223 - val_acc: 0.8838\n",
            "  \n",
            "------------------------ 9871.40575170517\n",
            "TrainEpochs number50/50\n",
            "390/390 [==============================] - 202s 518ms/step - loss: 0.2911 - acc: 0.8963 - val_loss: 0.3975 - val_acc: 0.8878\n",
            "  \n",
            "------------------------ 10073.596065282822\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
